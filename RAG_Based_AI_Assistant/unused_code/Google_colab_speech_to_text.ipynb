{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install/upgrade OpenAI Whisper package (latest version from PyPI)\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "# Update system package list and install FFmpeg (required for audio/video processing)\n",
        "!sudo apt update && sudo apt install -y ffmpeg"
      ],
      "metadata": {
        "id": "UqhIHtNevbT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVTecDr9ZDXb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Use v2-8TPU\n",
        "\n",
        "# Mount Google Drive to access files stored in your Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the directory containing converted audio files\n",
        "audios_p = '/content/drive/MyDrive/Colab_Notebooks/RAG_AI/converted_audios'\n",
        "\n",
        "# Get list of all audio files in the specified directory\n",
        "audios = os.listdir(audios_p)\n",
        "\n",
        "import whisper\n",
        "import json\n",
        "import torch\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Check for GPU availability (important for Whisper speed)\n",
        "# ----------------------------------------------------------\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(f\"üéØ Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üéØ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"‚ö†Ô∏è Using CPU - performance will be slow\")\n",
        "\n",
        "# Free up any leftover GPU memory before loading the model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Load Whisper large-v2 model (runs faster on GPU)\n",
        "# ----------------------------------------------------------\n",
        "print(\"Loading Whisper large-v2 model...\")\n",
        "model = whisper.load_model(\"large-v2\", device=device)\n",
        "print(f\"‚úÖ Model loaded on {device.upper()}\")\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Process each audio file in the directory\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "file_count = 0\n",
        "\n",
        "for audio in audios:\n",
        "    # Skip specific sample file if present\n",
        "    if audio == \"sample1.mp3\":\n",
        "        continue\n",
        "\n",
        "    # Extract numeric ID and title from filename\n",
        "    number = audio.split(\"_\")[0]\n",
        "    title = audio[:-4]   # remove file extension (.mp3)\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # Transcribe & translate audio using Whisper\n",
        "    # - language=\"hi\" ‚Üí input audio is Hindi\n",
        "    # - task=\"translate\" ‚Üí output is English translation\n",
        "    # - fp16=True ‚Üí enables faster half-precision on GPU\n",
        "    # ------------------------------------------------------\n",
        "    result = model.transcribe(\n",
        "        audio=f\"/content/drive/MyDrive/Colab_Notebooks/RAG_AI/converted_audios/{audio}\", # Path to audio file\n",
        "        # audio=\"/content/drive/MyDrive/Colab_Notebooks/RAG_AI/converted_audios/sample1.mp3\", # Example for testing\n",
        "        language=\"hi\",\n",
        "        task=\"translate\",\n",
        "        word_timestamps=False,\n",
        "        fp16=True if device == \"cuda\" else False\n",
        "    )\n",
        "\n",
        "    # Collect structured transcript segments with metadata\n",
        "    chunks = []\n",
        "    for segment in result[\"segments\"]:\n",
        "        chunks.append({\n",
        "            \"number\": number,\n",
        "            \"title\": title,\n",
        "            \"start\": segment[\"start\"],   # segment start time (sec)\n",
        "            \"end\": segment[\"end\"],       # segment end time (sec)\n",
        "            \"text\": segment[\"text\"]      # transcribed text\n",
        "        })\n",
        "\n",
        "    # Wrap chunks + full transcription into one JSON object\n",
        "    chunks_with_metadata = {\n",
        "        \"text\": result[\"text\"],   # full transcript\n",
        "        \"chunks\": chunks          # segmented transcript with timestamps\n",
        "    }\n",
        "\n",
        "    # ------------------------------------------------------\n",
        "    # Save transcription results as JSON in Google Drive\n",
        "    # ------------------------------------------------------\n",
        "    output_dir = '/content/drive/MyDrive/Colab_Notebooks/RAG_AI/jsons'\n",
        "    os.makedirs(output_dir, exist_ok=True)  # create directory if missing\n",
        "\n",
        "    # Define JSON output path (same name as audio file, but .json)\n",
        "    output_path = os.path.join(output_dir, f\"{audio.split('.')[0]}.json\")\n",
        "\n",
        "    # Write JSON file with UTF-8 encoding (keeps Hindi/Unicode safe)\n",
        "    with open(output_path, \"w\", encoding='utf-8') as f:\n",
        "        json.dump(chunks_with_metadata, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    file_count += 1\n",
        "    print(f\"{file_count} Done...\")\n"
      ]
    }
  ]
}